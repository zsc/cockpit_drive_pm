# Chapter 2｜用户体验蓝图与核心场景 (User Experience Blueprint & Core Scenarios)

## 1. 开篇段落
本章是“驾舱一体”项目的灵魂所在。我们将从用户视角出发，定义从“自然语言对话”到“自动驾驶行为”的完整交互逻辑。在将端到端（E2E）自动驾驶与大模型（LLM）结合时，产品设计的核心矛盾在于：**LLM 的“概率性/创造性”与自动驾驶的“确定性/安全性”之间的张力**。

本章的目标不是罗列功能，而是建立一套**可信赖的协作机制**。学习本章后，你将能够：
1.  构建分级的用户权限体系，明确“谁能控制方向盘”。
2.  绘制“对话→意图→确认→执行”的闭环时序图。
3.  定义在不同自动驾驶等级（L2/L2+/L3）下的 HMI（人机交互）适配规范。
4.  设计出优雅的“兜底体验”，处理幻觉和失败场景。

---

## 2. 文字论述

### 2.1 用户角色与权限矩阵 (User Roles & Permission Matrix)

在传统车机中，语音助手往往不区分说话人。但在“驾舱一体”中，语音指令可能改变车辆物理轨迹，因此**声纹识别（Voiceprint ID）**与**座位感知**是前置条件。

我们需要在 PRD 中定义如下权限矩阵（Rule-of-Thumb: **安全归主驾，娱乐归全员**）：

| 权限维度 | 驾驶员 (Driver) | 副驾 (Co-pilot) | 后排乘客 (Passenger) | 访客/未知 (Guest) |
| :--- | :--- | :--- | :--- | :--- |
| **导航-目的地修改** | ✅ 直接执行/确认 | ⚠️ 需主驾确认/仅推荐 | ❌ 仅能推荐 POI 到屏幕 | ❌ 无权 |
| **导航-添加途经点** | ✅ 直接执行 | ✅ 直接执行 | ⚠️ 需授权 | ❌ 无权 |
| **驾驶模 (运动/舒适)** | ✅ 直接执行 | ❌ 无权 | ❌ 无权 | ❌ 无权 |
| **智驾控制 (开启/接管)** | ✅ **最高优先级** | ❌ 严禁触碰 | ❌ 严禁触碰 | ❌ 严禁触碰 |
| **车控-全局 (车窗/门锁)** | ✅ 直接执行 | ⚠️ 仅控副驾侧 | ❌ 仅控本侧 | ❌ 仅控本侧 |
| **多媒体 (切歌/音量)** | ✅ 直接执行 | ✅ 直接执行 | ✅ 区域音区隔离 | ⚠️ 受限 |

> **关键决策点**：当后排乘客说“我要去机场”时，系统不应直接导航，而应回复：“已找到机场路线，请驾驶员确认出发。”

### 2.2 全链路场景地图 (Detailed Scenario Map)

我们将用户旅程细化为 **Intent (意图)** -> **Processing (编排)** -> **Interaction (交互)** -> **Execution (执行)** 四个泳道。

#### 核心场景：出发 (The Departure) - 模糊意图处理
*   **User**: "带我去个评价好的日料店，稍微远点没关系，要在海边。"
*   **LLM Analysis**:
    *   *Main Intent*: Navigation.
    *   *Constraints*: Category="Japanese", Rating="High", Location="Seaside", Distance=">5km".
*   **Strategy**: LLM 无法通过一次 API 命中唯一结果，需进入**“推荐与选择”模式**。

#### 核心场景：途中 (En-route) - 动态变更与确认
*   **User**: "前面好像堵车了，换条路吧。"
*   **Context**: 结合当前车辆位置、前方路况数据。
*   **Action**: 触发 Re-routing 工具。
*   **Risk**: 此时车辆正在运动，交互必须**极简**。

### 2.3 核心体验原则 (The "SAFE" Principles)

1.  **S - Safety First (安全优先)**：任何对话弹窗不得遮挡 SR（环境感知）界面的核心警示区（如盲区报警）。AD 接管请求（Takeover Request）拥有最高打断级。
2.  **A - Attention Management (注意力管理)**：车速越快，屏幕字越大，选项越少，语音播报越简洁。
3.  **F - Feedback Loop (闭环反馈)**：指令接收 -> 思考中 -> 准备就绪 -> 倒计时 -> 执行。每个状态都需有明确馈（声/光/图）。
4.  **E - Explainability (可解释性)**：如果车辆突然减速或变道（由 LLM 建议），屏幕必须显示原因（例：“正在为您驶向右侧出口”）。

### 2.4 深度解析：对话上下文导航升级方案

这是本项目将“App导航”升级为“智能导航”的关键。

#### 2.4.1 交互时序逻辑 (The Interaction Protocol)

引入 **“置信度分级确认机制”**，解决“啰嗦”与“不安全”的矛盾。

```ascii
[User Input] --> [LLM Analysis] --> [Confidence Score 计算]
                                          |
        +---------------------------------+--------------------------------+
        | (Score > 90% & Low Risk)        | (Score < 90% OR High Risk)     |
        v                                 v                                v
[Level 1: 隐式确认]               [Level 2: 倒计时确认]            [Level 3: 显式确认]
(e.g., "调低音量")                (e.g., "导航回家")              (e.g., "去陌生地址")
        |                                 |                                |
[TTS]: "好的" + 立即执行            [UI]: 弹窗 + "5秒后出发"         [UI]: 显示列表
                                  [TTS]: "准备去公司..."           [TTS]: "找到三个地点..."
                                          |                                |
                                  [User]: 无操作/点X               [User]: "第一个/确定"
                                          |                                |
                                  [Action]: 执行                    [Action]: 执行
```

#### 2.4.2 记忆与指代 (Context & Reference)
LLM 必须维护一个 `Session State`。
*   **Case 1**: User: "去国贸。" -> Agent: 推荐路线 A/B/C。 -> User: "**走最快的那个**。" (指代上轮的选项)。
*   **Case 2**: User: "先去接老婆。" -> Agent: "请问去哪里接？" -> User: "**还是老地方**。" (检索 Long-term Memory 中的高频地址)。

### 2.5 座舱多域融合：从“指令”到“任务编排”

座舱不再是孤立的 App 集合，LLM 是调度中心。

**场景：上班通勤模式**
*   **User**: "早安，我去上班，有点困。"
*   **LLM Task Chain**:
    1.  **Nav**: 设目的地为“公司”（基于时间习惯）。
    2.  **Route Preference**: 选择“时间最短”策略。
    3.  **Climate**: 调低温度 2度，增大风量（应对“困”）。
    4.  **Media**: 播放“新闻/快节奏音乐”收藏夹。
    5.  **TTS**: "早安，已规划避堵路线，全程40分钟。帮你开了提神模式。"

> **Rule of Thumb**: 复合指令执行时，**先执行“即时反馈”类**（如开空调、语音回复），**后执行“长时延”类**（如加载导航、搜索音乐），减少用户等待焦虑。

### 2.6 驾驶状态感知交互 (HMI Adaptation)

根据车辆状态（Vehicle State）动态调整 UI/UX。

| 车辆状态 | UI 布局特征 | 语音策略 | 交互限制 |
| :--- | :--- | :--- | :--- |
| **P档 / 驻车** | 内容丰富，大图，允许全键盘输入，支持视频。 | 被动响应为主，允许详细播报。 | 无限制。 |
| **D档 + 低速 (<30km/h)** | 列表模式，字号中等，禁用视频，启用手写板。 | 简短对话。 | 禁用设置菜单深层级。 |
| **D档 + 高速 (>80km/h)** | **卡片模式**（Card UI），超大字体，仅显示关键信息。 | **主动语音引导**（"请看屏幕..."）。 | 禁用一切复杂触控，强制语音交互。 |
| **AD 领航模式 (NOA)** | 沉浸式 SR 界面，强调“车辆意图”可视化。 | 语音作为“副驾驶”汇报决策。 | 允许部分娱乐功能（视法规L3而定）。 |

### 2.7 多模态呈现规范 (Multimodal Output)

*   **视觉 (Visual)**:
    *   **HMI/中控**: 承载列表、地图详情、设置项。
    *   **HUD (抬头显示)**: 仅显示**下一步动作**（如：右转箭头 + 剩余距离）和**状态确认**（如：麦克风图标闪烁）。*切忌在 HUD 显示复杂的餐厅列表。*
*   **听觉 (Auditory)**:
    *   **TTS**: 必须口语化，去除 JSON 风格的机械感。
    *   **Sound Cons**: 操作成功/失败/警告必须有差异化的提示音（Earcons），即使用户不看屏幕也能感知结果。

### 2.8 失败与兜底体验 (Graceful Degradation)

这是产品经理最需关注的“坑”。

1.  **模型幻觉/不支持的意图**：
    *   当 LLM 编造了一个不存在的车辆功能（如“开启飞行模式”）。
    *   **兜底**: 检测到 Action 不在白名单 -> 回复通用拒识话术：“抱歉，我现在还不会飞，但我可以帮你切换到运动模式。”
2.  **导航不可达**：
    *   当 E2E 自驾系统反馈“无法规划路径”（如目的地在军事禁区或未铺装路面）。
    *   **兜底**: LLM 解释原因：“自驾系统反馈该区域无法通行，已为您导航到最近的可停车点，剩余路程建议手动驾驶。”
3.  **确认超时**：
    *   高风险操（修改目的地）倒计时结束，用户未说话。
    *   **策略**: **默认为取消**。保持当前路线，不做变更，并提示“已保持原路线”。

### 2.9 指标口径与埋点 (UX Metrics)

在 PRD 中需定义以下埋点事件（Event Tracking）：
*   `voice_session_start`: 唤醒
*   `intent_classified`: 意图分类结果 (Nav/Chat/Control)
*   `slot_filling_rate`: 槽位填充率 (是否一次性提取了地点)
*   `confirmation_popup_show`: 确认卡片曝光
*   `confirmation_result`: 用户点击确定/取消/语音确认/超时
*   `navigation_start_success`: 导航成功开启
*   `intervention_after_nav`: 开启导航后 1分钟内的人工接管（表征导航不符合预期）

---

## 3. 本章小结

本章构建了驾舱一体体验的“骨架”。
*   **核心思想**：大模型负责“理解与建议”，传统规则/自驾域负责“约束与执行”。
*   **关键机制**：置信度分级确认（Confidence-based Confirmation）是平衡体验与全的关键。
*   **设计红线**：绝不让 AI 在未经确认的情况下改变车辆的物理运动状态（除非是极低风险的微调，且在自动驾驶能力范围内）。

---

## 4. 练习题

### 基础题 (50%)

1.  **[选择题]** 车辆处于 **NOA (自动领航)** 模式，时速 100km/h。此时用户通过语音请求“把屏幕亮度调到最亮，并搜索附近的五星级酒店”。以下哪种系统反应是**最不恰当**的？
    *   A. 调整亮度，并语音播报“亮度已调高”。
    *   B. 语音回应“已找到 5 家酒店”，并在中控屏弹出包含详细图片、评价文本的复杂可滚动列表。
    *   C. 语音回应“已找到 5 家酒店，最近的一家是万豪，要导航去吗？”，屏幕仅显示极简卡片。
    *   D. 调整亮度，并提示“为了安全，请稍后查看酒店详情”或仅推送到手机 App。
    <details><summary>点击查看答案与提示</summary>
    **答案**: B
    **提示**: 高速行驶（即使是NOA）严禁让驾驶员进行复杂的视觉搜索和阅读（Visual Distraction）。详细列表应被“压缩”或“阻断”。
    </details>

2.  **[填空题]** 在驾舱一体的权限设计中，涉及**车辆运动控制**（如变道、导航变更）的指令，必须由 _______ 发起或授权；而涉及**后排区域空调/娱乐**的指令，可以由 _______ 独立控制。
    <details><summary>点击查看答案与提示</summary>
    **答案**: 驾驶员 (Driver)；后排乘客 (Passenger)
    **提示**: 权责分明，安全归主驾，舒适归个人。
    </details>

3.  **[判断题]** 为了体现智能，当用户说“我想去吃火锅”时，系统应当根据用户画像，直接计算出一个最佳地点，并自动静默发起导航，无需用户任何确认。
    <details><summary>点击查看答案与提示</summary>
    **答案**: 错误 (False)
    **提示**: 导航变更属于高风险操作，且饮食偏好主观性强，必须保留“确认”节（哪怕是倒计时确认），给予用户撤销的机会。
    </details>

4.  **[简答题]** 请解释什么是 **"TTS 与 UI 的多模态一致性"**，并举一个反例。
    <details><summary>点击查看答案与提示</summary>
    **答案**: 指语音播报的内容（听觉）与屏幕显示的信息（视觉）在关键信息点上保持同步和一致，避免认知冲突。
    **反例**: TTS 播报“为您推荐了三条路线，第一条时间最短”，但屏幕上高亮显示的却是“费用最少”的那条路线，或者屏幕列表顺序与语音播报顺序不一致。
    </details>

### 挑战题 (50%)

5.  **[场景设计]** 设计一个 **"多意图冲突仲裁"** 的逻辑。
    *   **背景**: 主驾说“太热了”，副驾几乎同时说“太冷了”。
    *   **任务**: 设计 Agent 的处理流程，包括语音识别处理、意图理解、策略仲裁和最终执行反馈。
    <details><summary>点击查看答案与提示</summary>
    **参考答**:
    1. **ASR (声纹分离)**: 识别到两个不同声源（Zone 1 & Zone 2）。
    2. **Intent NLU**: Zone 1 -> `Climate_Cool_Down`; Zone 2 -> `Climate_Heat_Up`.
    3. **策略仲裁 (Policy Engine)**:
       - 检查车辆是否支持**双温区/多温区独立控制**。
       - **If yes**: 分区执行。主驾出风口调低 2度，副驾出风口调高 2度。
       - **If no** (单温区): **主驾优先原则**，或者取折中值，或者询问。通常倾向于主驾优先，或提示“正在折中调节”。
    4. **反馈 (TTS)**: “已为主驾调低温度，副驾调高温度。” (若支持分区)。
    **提示**: 硬件能力（是否双温区）决定了软件策略。
    </details>

6.  **[时序图绘制]** 绘制一个包含 **"E2E 自驾执行失败"** 的交互流程。
    *   用户：“开到前面那个小土坡上去。” (意图：Off-road 模式 / 导航到非道路区域)
    *   LLM：识别意图，生成坐标。
    *   AD System：评估地形，返 `Unreachable / Risk High`。
    *   请描述后续系统如何反馈。
    <details><summary>点击查看答案与提示</summary>
    **参考思路**:
    1. **User**: "开到那个土坡上去。"
    2. **Agent**: Tool Call `Navigate(target='土坡坐标')`。
    3. **AD Interface**: 接收坐标 -> 路径规划 -> **Return Error**: `Code: TERRAIN_UNSUPPORTED, Msg: Slope too steep`.
    4. **Agent**: 捕获错误码，映射到话术。
    5. **TTS/UI**: "自驾系统评估前方坡度过大，无法自动驶入。已切换为手动驾驶模式，请您接管方向盘。"
    6. **HMI**: 仪表盘显示接管提示，自驾指示灯熄灭。
    **提示**: 关键在于 LLM 要能“看懂”AD 系统返回的错误码，并将其翻译成人话。
    </details>

7.  **[开放思考题]** 现在的 E2E 自驾通常是 "Vision -> Action" 黑盒。如果引入驾舱一体，我们需要 LLM 能够解释 AD 的行为（例如车为什么突然停了）。请列出为了实现 **"可解释性 (Explainability)"**，自驾域（AD Domain）至少需要向座舱域（Cockpit Domain）实时共享哪些数据？
    <details><summary>点击查看答案与提示</summary>
    **参考答案**:
    必须共享 **World Model (世界模型)** 的高层语义信息，包括但不限于：
    1. **感知对象**: 识别到的障碍物类型（行人/狗/锥桶/事故车）。
    2. **决策意图**: 接下来 3-5秒的规划动作（准备左转/准备避让/准备停车）。
    3. **状态原因**: `Stop_Reason` (红灯/斑马线礼让/前车急刹)。
    *例子*: 车停了 -> LLM 读取 `Stop_Reason`="Yield to Pedestrian" -> TTS: "正在礼让行人，请稍等。"
    **提示**: 纯端到端模型往往缺乏中间语义，这正是当前技术整合的难点，可能需要一个独立的“解释器模型”。
    </details>

---

## 5. 常见陷阱与错误 (Gotchas)

### 5.1 "过度拟人化" (Over-Anthropomorphism)
*   **错误**: LLM 模拟过于像人，使用“我累了”、“我不想去等情绪化表达，或者在 AD 接管时开玩笑。
*   **修正**: 在涉及控车和安全时，保持**专业、冷静、客观**的 "Co-pilot" 人设。虽然是 LLM，但必须展现出机器的可靠性。

### 5.2 忽略声纹漂移 (Voiceprint Drift)
*   **错误**: 假设声纹识别 100% 准确。实际上，噪音、感冒、大声喊叫都可能导致识别错误。
*   **修正**: 对于**高风险操作（High Stakes）**，即使声纹匹配了，最好还是增加一步**物理确认**（如“请按方向盘确认键”或屏幕点击），形成双因子认证（2FA）。

### 5.3 抢占音频焦点 (Audio Focus Fighting)
*   **错误**: 导航正在播报关键路口指引，LLM 突然插嘴说“为你推荐一首好听的歌”。
*   **修正**: 建立严格的 **Audio Focus Manager**。
    *   **Priority 1 (Safety)**: 碰撞预警、接管提示 (压低所有声音)。
    *   **Priority 2 (Nav)**: 导航播报 (压低媒体音量)。
    *   **Priority 3 (Interaction)**: 用唤醒、语音回复 (压低媒体)。
    *   **Priority 4 (Media)**: 音乐、电台。
    *   *LLM 的闲聊/推荐属于 Priority 3，必须给 Nav 让路。*

### 5.4 屏幕信息过载 (Information Overload)
*   **错误**: LLM 为了展示自己很聪明，把搜索到的 500 字大众点评评论全部显示在屏幕上。
*   **修正**: 强制 **Summary (摘要)**。LLM 的输出必须经过一个 formatter，针对车机屏幕尺寸生成摘要版（如不超过 50 字），且支持 TTS 朗读核心点。

### 5.5 "我知道了" 但不做 (Acknowledgment without Action)
*   **错误**: 用户说“打开空调”，TTS 说“好的”，但底层 CAN 信号因总线拥堵丢包，实际没开。用户以为开了，体验极差。
*   **修正**: **闭环检测**。Agent 发出指令后，必须监听车辆状态回执（State Callback）。只有传感器真的反馈“空调已开”，才能说“已打开”；否则应报“指令执行超时，请重试”。
